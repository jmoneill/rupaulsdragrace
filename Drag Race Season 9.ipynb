{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rupaul's Drag Race Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "from scipy.stats import rankdata, kendalltau\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "theData = pd.read_csv(\"dragrace9.csv\")\n",
    "theData= theData.fillna(0)\n",
    "#theData.iloc[1:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queens = theData\n",
    "queens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a function to scale the data for us\n",
    "def scaleQueens(df):\n",
    "    \"\"\"Scale Age, Wins, Highs, Lows, and Lipsyncs in feature data frames\"\"\"\n",
    "    df = df.copy(deep=True)\n",
    "    df['Age'] = scale(df['Age'])\n",
    "    df['Wins'] = scale(df['Wins'])\n",
    "    df['Highs'] = scale(df['Highs'])\n",
    "    df['Lows'] = scale(df['Lows'])\n",
    "    df['Lipsyncs'] = scale(df['Lipsyncs'])\n",
    "    df['Season'] = df['Season']/9\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compareRanks(x,y):\n",
    "    \"\"\"x = actual, y = predicted place\"\"\"\n",
    "    x=np.asarray(x)\n",
    "    y=np.asarray(y)\n",
    "    numRanks = np.append(x,y).max()\n",
    "    actual=np.sum(np.square(x-y))\n",
    "    worst=np.sum(np.square(np.sort(x)-np.sort(x)[::-1]))\n",
    "    return 1-2*(actual/worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rankScore(model,x,y):\n",
    "    ypred = model.predict(x)\n",
    "    score = compareRanks(y,ypred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createPD(s,queens,yfitpd):\n",
    "    season = queens.loc[queens.Season==s,['Name','Place']]\n",
    "    seasonpred = yfitpd.loc[queens.Season==s]\n",
    "    season['Predicted'] = seasonpred\n",
    "    season['Predicted'] = rankdata(season.Predicted,method='min')\n",
    "    season = season.sort_values('Place')\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictSeason(season,model,queens,scaled=False):\n",
    "    Xtrain = queens.loc[queens.Season!=season,['Age','PuertoRico','PlusSize','Wins','Highs','Lows','Lipsyncs','Season']]\n",
    "    Xtest = queens.loc[queens.Season==season,['Age','PuertoRico','PlusSize','Wins','Highs','Lows','Lipsyncs','Season']]\n",
    "    ytrain = queens.loc[queens.Season!=season,'Place']\n",
    "    if scaled:\n",
    "        Xtrain = scaleQueens(Xtrain)\n",
    "        Xtest = scaleQueens(Xtest)\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    yfit = model.predict(Xtest)\n",
    "    pddf = queens.loc[queens.Season==season,['Name','Place']]\n",
    "    pddf['Predicted'] = rankdata(yfit,method='min')\n",
    "    return pddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class neural_network:\n",
    "    \"\"\"Defines a neural network, along with attributes for fitting and predicting the network\"\"\"\n",
    "    def __init__(self,size):\n",
    "        random.seed(0)\n",
    "        self.network = []\n",
    "        for i in range(1,len(size)):\n",
    "            self.network.append([[random.random() for __ in range(size[i-1] + 1)] for __ in range(size[i])])\n",
    "    \n",
    "    def sigmoid(self,t): \n",
    "        return 1 / (1 + math.exp(-t))\n",
    "    \n",
    "    def neuron_output(self,weights, inputs):   #This is a simpler representation; weights for input plus one extra (bias)\n",
    "        return self.sigmoid(np.dot(weights, inputs))\n",
    "    \n",
    "    def feed_forward(self,input_vector):\n",
    "        outputs = []\n",
    "\n",
    "        for layer in self.network: #Remember the neural network is given as a list of \"layers\" which have neurons in them\n",
    "\n",
    "            input_with_bias = input_vector + [1]          # add a bias input (this just allos us to use a dot product)\n",
    "            output = [self.neuron_output(neuron, input_with_bias) # compute the output\n",
    "                      for neuron in layer]                   # for this layer\n",
    "            outputs.append(output)                           # and remember it\n",
    "\n",
    "            # the input to the next layer is the output of this one\n",
    "            input_vector = output\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X = scaleQueens(X)\n",
    "        predictedY = []\n",
    "        X = X.values.tolist()\n",
    "        for i, input in enumerate(X):\n",
    "            outputs = self.feed_forward(input)[-1]\n",
    "            predictedY.append(outputs)\n",
    "        predictedPlace = [a.index(max(a)) for a in predictedY]\n",
    "        return predictedPlace\n",
    "    \n",
    "    \n",
    "    def convertY(self,Y):\n",
    "        yNN = [[1 if i == (j-1) else 0 for i in range(0,len(Y)-1)]\n",
    "               for j in Y ]\n",
    "        return(yNN)\n",
    "    \n",
    "    # define the back-propagation that allows the network to learn\n",
    "    def backpropagate(self, input_vector, target):\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector)\n",
    "\n",
    "        # the output * (1 - output) is from the derivative of sigmoid\n",
    "        output_deltas = [output * (1 - output) * (output - target[i])\n",
    "                         for i, output in enumerate(outputs)]\n",
    "\n",
    "        # adjust weights for output layer (network[-1])\n",
    "        for i, output_neuron in enumerate(self.network[-1]):\n",
    "            for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "                output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "\n",
    "        # back-propagate errors to hidden layer\n",
    "        hidden_deltas = [hidden_output * (1 - hidden_output) * \n",
    "                          np.dot(output_deltas, [n[i] for n in self.network[-1]]) \n",
    "                         for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "        # adjust weights for hidden layer (network[0])\n",
    "        for i, hidden_neuron in enumerate(self.network[0]):\n",
    "            for j, input in enumerate(input_vector + [1]):\n",
    "                hidden_neuron[j] -= hidden_deltas[i] * input\n",
    "    \n",
    "    def fit(self,features,targets,times=10000):\n",
    "        features = scaleQueens(features)\n",
    "        targets = self.convertY(targets)\n",
    "        features = features.values.tolist()\n",
    "        for i in range(times):\n",
    "            for X, Y in zip(features, targets):\n",
    "                self.backpropagate(X,Y)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class neural_network:\n",
    "    \"\"\"Defines a neural network, along with attributes for fitting and predicting the network\"\"\"\n",
    "    def __init__(self,model):\n",
    "        self.network = model\n",
    "    \n",
    "    def sigmoid(self,t): \n",
    "        return 1 / (1 + math.exp(-t))\n",
    "    \n",
    "    def neuron_output(self,weights, inputs):   #This is a simpler representation; weights for input plus one extra (bias)\n",
    "        return self.sigmoid(np.dot(weights, inputs))\n",
    "    \n",
    "    def feed_forward(self,input_vector):\n",
    "        outputs = []\n",
    "\n",
    "        for layer in self.network: #Remember the neural network is given as a list of \"layers\" which have neurons in them\n",
    "\n",
    "            input_with_bias = input_vector + [1]          # add a bias input (this just allos us to use a dot product)\n",
    "            output = [self.neuron_output(neuron, input_with_bias) # compute the output\n",
    "                      for neuron in layer]                   # for this layer\n",
    "            outputs.append(output)                           # and remember it\n",
    "\n",
    "            # the input to the next layer is the output of this one\n",
    "            input_vector = output\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self,X):\n",
    "        predictedY = self.network.predict(X)\n",
    "        return predictedY\n",
    "    \n",
    "    \n",
    "    def convertY(self,Y):\n",
    "        yNN = [[1 if i == (j-1) else 0 for i in range(0,len(Y)-1)]\n",
    "               for j in Y ]\n",
    "        return(yNN)\n",
    "    \n",
    "    # define the back-propagation that allows the network to learn\n",
    "    def backpropagate(self, input_vector, target):\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector)\n",
    "\n",
    "        # the output * (1 - output) is from the derivative of sigmoid\n",
    "        output_deltas = [output * (1 - output) * (output - target[i])\n",
    "                         for i, output in enumerate(outputs)]\n",
    "\n",
    "        # adjust weights for output layer (network[-1])\n",
    "        for i, output_neuron in enumerate(self.network[-1]):\n",
    "            for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "                output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "\n",
    "        # back-propagate errors to hidden layer\n",
    "        hidden_deltas = [hidden_output * (1 - hidden_output) * \n",
    "                          np.dot(output_deltas, [n[i] for n in self.network[-1]]) \n",
    "                         for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "        # adjust weights for hidden layer (network[0])\n",
    "        for i, hidden_neuron in enumerate(self.network[0]):\n",
    "            for j, input in enumerate(input_vector + [1]):\n",
    "                hidden_neuron[j] -= hidden_deltas[i] * input\n",
    "    \n",
    "    def fit(self,features,targets,times=10000):\n",
    "        targets = self.convertY(targets)\n",
    "        self.network.fit(features,targets)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "svc_model = SVC(kernel='rbf',gamma=0.01,C=10)\n",
    "gnb_model = GaussianNB()\n",
    "rfc_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rfr_model = RandomForestRegressor(200,random_state=24601)\n",
    "#nn_model = neural_network([8,5,14])\n",
    "nn2_model=MLPClassifier(hidden_layer_sizes=(5,),\n",
    "                       activation='logistic',\n",
    "                       solver='lbfgs',\n",
    "                       random_state=24601)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have each model predict the rankings and save to a data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Aja</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Alexis Michelle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Charlie Hides</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Eureka</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Farrah Moan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Jaymes Mansfield</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Kimora Blac</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Nina Bo'Nina Brown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Peppermint</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Sasha Velour</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Shea Coulee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Trinity Taylor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Valentina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  Place  Predicted\n",
       "101                 Aja    0.0          1\n",
       "102     Alexis Michelle    0.0         11\n",
       "103       Charlie Hides    0.0          9\n",
       "104              Eureka    0.0          4\n",
       "105         Farrah Moan    0.0          1\n",
       "106    Jaymes Mansfield    0.0          4\n",
       "107         Kimora Blac    0.0          4\n",
       "108  Nina Bo'Nina Brown    0.0         11\n",
       "109          Peppermint    0.0          9\n",
       "110        Sasha Velour    0.0          4\n",
       "111         Shea Coulee    0.0          4\n",
       "112      Trinity Taylor    0.0         11\n",
       "113           Valentina    0.0          1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictSeason(9,nn2_model,queens,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "the_models = [gnb_model,rfc_model,rfr_model,nn2_model]\n",
    "model_names = [\"GNB\",\"RFC\",\"RFR\",\"NN\"]\n",
    "season = predictSeason(9,svc_model,queens,True)\n",
    "season['Season'] = 9\n",
    "season['Model'] = 'SVC'\n",
    "rank_score = compareRanks(season.Place,season.Predicted)\n",
    "rsdf = pd.DataFrame({'Season': [9], 'Value': [rank_score], 'Model': ['SVM']})\n",
    "pred_df = season\n",
    "rank_scores = rsdf.copy(deep=True)\n",
    "n = 0\n",
    "for model in the_models:\n",
    "    season = predictSeason(9,model,queens,True)\n",
    "    season['Season'] = 9\n",
    "    season['Model'] = model_names[n]\n",
    "    pred_df = pred_df.append(season)\n",
    "    rank_score = compareRanks(season.Place,season.Predicted)\n",
    "    rsdf = pd.DataFrame({'Season': [9], 'Value': [rank_score], 'Model': [model_names[n]]})\n",
    "    rank_scores = rank_scores.append(rsdf)\n",
    "    n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Season</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Predicted</th>\n",
       "      <th>mean</th>\n",
       "      <th>PredPlace</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GNB</th>\n",
       "      <th>NN</th>\n",
       "      <th>RFC</th>\n",
       "      <th>RFR</th>\n",
       "      <th>SVC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kimora Blac</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Valentina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shea Coulee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Hides</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farrah Moan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aja</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peppermint</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sasha Velour</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexis Michelle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Trinity Taylor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nina Bo'Nina Brown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jaymes Mansfield</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eureka</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name Place Season Predicted                      mean  \\\n",
       "Model                                        GNB  NN RFC RFR SVC             \n",
       "6             Kimora Blac   0.0      9         1   4   1   1   3  2.714286   \n",
       "12              Valentina   0.0      9         1   1   1   5   3  2.857143   \n",
       "10            Shea Coulee   0.0      9         1   4   1   3   3  3.000000   \n",
       "2           Charlie Hides   0.0      9         1   9   1   1   1  3.142857   \n",
       "4             Farrah Moan   0.0      9         1   1   1   8   3  3.285714   \n",
       "0                     Aja   0.0      9         1   1   1   9   3  3.428571   \n",
       "8              Peppermint   0.0      9         1   9   1   4   1  3.571429   \n",
       "9            Sasha Velour   0.0      9         1   4   1  11   3  4.142857   \n",
       "1         Alexis Michelle   0.0      9         1  11   1   6   3  4.428571   \n",
       "11         Trinity Taylor   0.0      9         1  11   1   7   3  4.571429   \n",
       "7      Nina Bo'Nina Brown   0.0      9         1  11   1   9   3  4.857143   \n",
       "5        Jaymes Mansfield   0.0      9        12   4   1  12  12  7.142857   \n",
       "3                  Eureka   0.0      9        12   4   1  13  12  7.285714   \n",
       "\n",
       "      PredPlace  \n",
       "Model            \n",
       "6             1  \n",
       "12            2  \n",
       "10            3  \n",
       "2             4  \n",
       "4             5  \n",
       "0             6  \n",
       "8             7  \n",
       "9             8  \n",
       "1             9  \n",
       "11           10  \n",
       "7            11  \n",
       "5            12  \n",
       "3            13  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsTable = pred_df.pivot_table(index=('Name','Place','Season'),columns='Model').sortlevel(['Season','Place'])\n",
    "resultsTable = resultsTable.reset_index()\n",
    "resultsTable['mean'] = resultsTable.mean(axis=1)\n",
    "resultsTable['PredPlace'] = rankdata(resultsTable['mean'],method='min')\n",
    "resultsTable.to_csv('PredictedSeason9.csv')\n",
    "resultsTable.sort_values(by='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Season</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>9</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GNB</td>\n",
       "      <td>9</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RFC</td>\n",
       "      <td>9</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RFR</td>\n",
       "      <td>9</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>9</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Season  Value\n",
       "0   SVM       9   -inf\n",
       "0   GNB       9   -inf\n",
       "0   RFC       9   -inf\n",
       "0   RFR       9   -inf\n",
       "0    NN       9   -inf"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Based on Princess Points\n",
    "\n",
    "A group of drag race super fans scored the meet the queens videos for season 8, and then again for season 9. The results below train on season 8 only and then predict season 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictSeasonPrincess(season,model,queens,scaled=False):\n",
    "    Xtrain = queens.loc[queens.Season==8,['Age','PuertoRico','PlusSize','Season',\n",
    "                                          'Party Princess','Purity Princess','Draggity Princess','Blackout Princess',\n",
    "                                         'Cookie Princess','Bartender Princess']]\n",
    "    Xtest = queens.loc[queens.Season==9,['Age','PuertoRico','PlusSize','Season',\n",
    "                                          'Party Princess','Purity Princess','Draggity Princess','Blackout Princess',\n",
    "                                         'Cookie Princess','Bartender Princess']]\n",
    "    ytrain = queens.loc[queens.Season==8,'Place']\n",
    "    if scaled:\n",
    "        Xtrain = scaleQueensPrincess(Xtrain)\n",
    "        Xtest = scaleQueensPrincess(Xtest)\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    yfit = model.predict(Xtest)\n",
    "    pddf = queens.loc[queens.Season==9,['Name','Place']]\n",
    "    pddf['Predicted'] = rankdata(yfit,method='min')\n",
    "    return pddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a function to scale the data for us\n",
    "def scaleQueensPrincess(df):\n",
    "    \"\"\"Scale Age, Wins, Highs, Lows, and Lipsyncs in feature data frames\"\"\"\n",
    "    df = df.copy(deep=True)\n",
    "    df['Age'] = scale(df['Age'])\n",
    "    for princess in ['Party Princess','Purity Princess','Draggity Princess',\n",
    "                     'Blackout Princess','Cookie Princess','Bartender Princess']:\n",
    "        df[princess] = scale(df[princess])\n",
    "    df['Season'] = df['Season']/9\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/thomas/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "the_models = [gnb_model,rfc_model,rfr_model,nn2_model]\n",
    "model_names = [\"GNB\",\"RFC\",\"RFR\",\"NN\"]\n",
    "season = predictSeasonPrincess(9,svc_model,queens,True)\n",
    "season['Season'] = 9\n",
    "season['Model'] = 'SVC'\n",
    "rank_score = compareRanks(season.Place,season.Predicted)\n",
    "rsdf = pd.DataFrame({'Season': [9], 'Value': [rank_score], 'Model': ['SVM']})\n",
    "pred_df = season\n",
    "rank_scores = rsdf.copy(deep=True)\n",
    "n = 0\n",
    "for model in the_models:\n",
    "    if model_names[n] == \"GNB\" or model_names[n] == \"NN\":\n",
    "        season = predictSeasonPrincess(9,model,queens,True)\n",
    "    else:\n",
    "        season = predictSeasonPrincess(9,model,queens,False)\n",
    "    season['Season'] = 9\n",
    "    season['Model'] = model_names[n]\n",
    "    pred_df = pred_df.append(season)\n",
    "    rank_score = compareRanks(season.Place,season.Predicted)\n",
    "    rsdf = pd.DataFrame({'Season': [9], 'Value': [rank_score], 'Model': [model_names[n]]})\n",
    "    rank_scores = rank_scores.append(rsdf)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Season</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Predicted</th>\n",
       "      <th>Mean</th>\n",
       "      <th>PredPlace</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GNB</th>\n",
       "      <th>NN</th>\n",
       "      <th>RFC</th>\n",
       "      <th>RFR</th>\n",
       "      <th>SVC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie Hides</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farrah Moan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jaymes Mansfield</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eureka</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shea Coulee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Trinity Taylor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kimora Blac</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Valentina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexis Michelle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peppermint</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aja</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sasha Velour</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nina Bo'Nina Brown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name Place Season Predicted                      Mean  \\\n",
       "Model                                        GNB  NN RFC RFR SVC             \n",
       "2           Charlie Hides   0.0      9         3   1   1   7   1  3.142857   \n",
       "4             Farrah Moan   0.0      9         3   3   5   2   2  3.428571   \n",
       "5        Jaymes Mansfield   0.0      9         3   1   2   1   9  3.571429   \n",
       "3                  Eureka   0.0      9         3   7   2   5   3  4.142857   \n",
       "10            Shea Coulee   0.0      9         3   4   5   4   6  4.428571   \n",
       "11         Trinity Taylor   0.0      9         1   7   4  12   3  5.142857   \n",
       "6             Kimora Blac   0.0      9         3   6  10   6   3  5.285714   \n",
       "12              Valentina   0.0      9         3  10   5   3   9  5.571429   \n",
       "1         Alexis Michelle   0.0      9         2   5   8  10   7  5.857143   \n",
       "8              Peppermint   0.0      9         3   7   8   8   7  6.000000   \n",
       "0                     Aja   0.0      9         3  10  10   9   9  7.142857   \n",
       "9            Sasha Velour   0.0      9         3  10  10  11   9  7.428571   \n",
       "7      Nina Bo'Nina Brown   0.0      9         3  10  10  13   9  7.714286   \n",
       "\n",
       "      PredPlace  \n",
       "Model            \n",
       "2             1  \n",
       "4             2  \n",
       "5             3  \n",
       "3             4  \n",
       "10            5  \n",
       "11            6  \n",
       "6             7  \n",
       "12            8  \n",
       "1             9  \n",
       "8            10  \n",
       "0            11  \n",
       "9            12  \n",
       "7            13  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsTable = pred_df.pivot_table(index=('Name','Place','Season'),columns='Model').sortlevel(['Season','Place'])\n",
    "resultsTable = resultsTable.reset_index()\n",
    "resultsTable['Mean'] = resultsTable.mean(axis=1)\n",
    "resultsTable['PredPlace'] = rankdata(resultsTable['Mean'],method='min')\n",
    "resultsTable = resultsTable.sort_values(by='PredPlace')\n",
    "resultsTable.to_csv(\"princessPredictions9.csv\")\n",
    "resultsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg_results = resultsTable.Predicted.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_sigmoid = MLPClassifier(hidden_layer_sizes=(5,),\n",
    "                       activation='logistic',\n",
    "                       solver='lbfgs',\n",
    "                       random_state=24601)\n",
    "nn_relu = MLPClassifier(hidden_layer_sizes=(5,),\n",
    "                       activation='relu',\n",
    "                       solver='lbfgs',\n",
    "                       random_state=24601)\n",
    "nn_tanh = MLPClassifier(hidden_layer_sizes=(5,),\n",
    "                       activation='tanh',\n",
    "                       solver='lbfgs',\n",
    "                       random_state=24601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = queens.loc[queens.Season!=9,['Age','PuertoRico','PlusSize','Wins','Highs','Lows','Lipsyncs','Season']]\n",
    "Y = queens.loc[queens.Season!=9,'Place']\n",
    "\n",
    "train = queens.loc[queens.Season<8,['Age','PuertoRico','PlusSize','Wins','Highs','Lows','Lipsyncs','Season','Place']]\n",
    "test = queens.loc[queens.Season==8,['Age','PuertoRico','PlusSize','Wins','Highs','Lows','Lipsyncs','Season','Place']]\n",
    "\n",
    "Xtrain = train.loc[train.Season<8,:]\n",
    "Xtrain.drop('Place',axis=1,inplace=True)\n",
    "Xtest = test.loc[test.Season==8,:]\n",
    "Xtest.drop('Place',axis=1,inplace=True)\n",
    "ytrain = train.loc[train.Season<8,'Place']\n",
    "ytest = test.loc[test.Season==8,'Place']\n",
    "\n",
    "# Xtrain, Xtest, ytrain, ytest = train_test_split(X,Y,random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = scaleQueens(Xtrain)\n",
    "Xtest = scaleQueens(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 8)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 8)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=24601,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_sigmoid.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77735849056603779"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankScore(nn_sigmoid,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=24601,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_relu.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76226415094339628"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankScore(nn_relu,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=24601,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_tanh.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72452830188679251"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankScore(nn_tanh,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
